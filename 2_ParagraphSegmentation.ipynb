{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import random\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "import mxnet as mx\n",
    "import numpy as np\n",
    "#from skimage.draw import line_aa\n",
    "from skimage import transform as skimage_transform\n",
    "\n",
    "from mxnet import nd, autograd, gluon\n",
    "from mxnet.image import resize_short\n",
    "from mxboard import SummaryWriter\n",
    "\n",
    "\n",
    "from utilities.iam_dataset import IAMDataset\n",
    "from utilities.draw_box_on_image import draw_box_on_image\n",
    "\n",
    "model_checkpoint_folder = \"model_checkpoint\"\n",
    "model_export_folder = \"model_export\"\n",
    "if not os.path.isdir(model_checkpoint_folder):\n",
    "    os.makedirs(model_checkpoint_folder)\n",
    "if not os.path.isdir(model_export_folder):\n",
    "    os.makedirs(model_export_folder)\n",
    "    \n",
    "ctx = mx.gpu() if mx.context.num_gpus() > 0 else mx.cpu()\n",
    "mx.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = IAMDataset(\"form\", output_data=\"bb\", output_parse_method=\"form\", train=True)\n",
    "print(\"Number of training samples: {}\".format(len(train_ds)))\n",
    "\n",
    "test_ds = IAMDataset(\"form\", output_data=\"bb\", output_parse_method=\"form\", train=False)\n",
    "print(\"Number of testing samples: {}\".format(len(test_ds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "random_y_translation, random_x_translation = (0.2, 0.2) # Randomly translate the input image\n",
    "expand_bb_scale = 0.03 # Expand the bounding box "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(data, label):\n",
    "    '''\n",
    "    Function that converts \"data\"\" into the input image tensor for a CNN\n",
    "    Label is converted into a float tensor.\n",
    "    '''\n",
    "    image = mx.nd.array(data).expand_dims(axis=2)\n",
    "    image = resize_short(image, int(800/3))\n",
    "    image = image.transpose([2, 0, 1])/255.\n",
    "    label = label[0].astype(np.float32)\n",
    "    print(label)\n",
    "    \n",
    "    bb = label.copy()\n",
    "    new_w = (1 + expand_bb_scale) * bb[2]\n",
    "    new_h = (1 + expand_bb_scale) * bb[3]\n",
    "    \n",
    "    bb[0] = bb[0] - (new_w - bb[2])/2\n",
    "    bb[1] = bb[1] - (new_h - bb[3])/2\n",
    "    bb[2] = new_w\n",
    "    bb[3] = new_h\n",
    "\n",
    "    return image, mx.nd.array(bb)\n",
    "\n",
    "def augment_transform(data, label):\n",
    "    '''\n",
    "    Function that randomly translates the input image by +-width_range and +-height_range.\n",
    "    The labels (bounding boxes) are also translated by the same amount.\n",
    "    '''\n",
    "    ty = random.uniform(-random_y_translation, random_y_translation)\n",
    "    tx = random.uniform(-random_x_translation, random_x_translation)\n",
    "    st = skimage_transform.SimilarityTransform(translation=(tx*data.shape[1], ty*data.shape[0]))\n",
    "    data = skimage_transform.warp(data, st)\n",
    "    label = label.copy()\n",
    "    label[0][0] = label[0][0] - tx\n",
    "    label[0][1] = label[0][1] - ty\n",
    "    return transform(data*255., label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = mx.gluon.data.DataLoader([trans for trans in train_ds.transform(augment_transform)],\n",
    "                                      batch_size, shuffle=True, num_workers=0)\n",
    "test_data = mx.gluon.data.DataLoader([trans for trans in test_ds.transform(transform)],\n",
    "                                     batch_size, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SegmentationNetwork(gluon.nn.HybridBlock):\n",
    "    \n",
    "    def __init__(self, p_dropout = 0.5, ctx):\n",
    "        super(SegmentationNetwork, self).__init__()\n",
    "\n",
    "        pretrained = gluon.model_zoo.vision.resnet34_v1(pretrained=True, ctx=ctx)\n",
    "        first_weights = pretrained.features[0].weight.data().mean(axis=1).expand_dims(axis=1)\n",
    "        \n",
    "\n",
    "        body = gluon.nn.HybridSequential(prefix=\"SegmentationNetwork_\")\n",
    "        with body.name_scope():\n",
    "            first_layer = gluon.nn.Conv2D(channels=64, kernel_size=(7, 7), padding=(3, 3), strides=(2, 2), in_channels=1, use_bias=False)\n",
    "            first_layer.initialize(mx.init.Normal(), ctx=ctx)\n",
    "            first_layer.weight.set_data(first_weights)\n",
    "            body.add(first_layer)\n",
    "            body.add(*pretrained.features[1:6])\n",
    "        \n",
    "            output = gluon.nn.HybridSequential()\n",
    "            with output.name_scope():\n",
    "                output.add(gluon.nn.Flatten())\n",
    "                output.add(gluon.nn.Dense(64, activation='relu'))\n",
    "                output.add(gluon.nn.Dropout(p_dropout))\n",
    "                output.add(gluon.nn.Dense(64, activation='relu'))\n",
    "                output.add(gluon.nn.Dropout(p_dropout))\n",
    "                output.add(gluon.nn.Dense(4, activation='sigmoid'))\n",
    "\n",
    "            output.collect_params().initialize(mx.init.Normal(), ctx=ctx)\n",
    "            body.add(output)\n",
    "        self.cnn = body\n",
    "\n",
    "    def hybrid_forward(self, F, x):\n",
    "        return self.cnn(x)\n",
    "\n",
    "net = SegmentationNetwork()\n",
    "net.hybridize()\n",
    "net.collect_params().reset_ctx(ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_every_n = 10\n",
    "send_image_every_n = 20\n",
    "\n",
    "def run_epoch(e, network, dataloader, loss_function, trainer, log_dir, print_name, is_train):\n",
    "    total_loss = nd.zeros(1, ctx)\n",
    "    for i, (data, label) in enumerate(dataloader):\n",
    "        data = data.as_in_context(ctx)\n",
    "        label = label.as_in_context(ctx)\n",
    "        \n",
    "        with autograd.record(train_mode=is_train):\n",
    "            output = network(data)\n",
    "            loss_i = loss_function(output, label)\n",
    "        if is_train:\n",
    "            loss_i.backward()\n",
    "            trainer.step(data.shape[0])\n",
    "\n",
    "        total_loss += loss_i.mean()\n",
    "        \n",
    "        if e % send_image_every_n == 0 and e > 0 and i == 0:\n",
    "            output_image = draw_box_on_image(output.asnumpy(), label.asnumpy(), data.asnumpy())\n",
    "    epoch_loss = float(total_loss .asscalar())/len(dataloader)\n",
    "    \n",
    "    with SummaryWriter(logdir=log_dir, verbose=False, flush_secs=5) as sw:\n",
    "        sw.add_scalar('loss', {print_name: epoch_loss}, global_step=e)\n",
    "        if e % send_image_every_n == 0 and e > 0:\n",
    "            output_image[output_image<0] = 0\n",
    "            output_image[output_image>1] = 1\n",
    "            sw.add_image('bb_{}_image'.format(print_name), output_image, global_step=e)\n",
    "            \n",
    "    return epoch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_name = \"cnn_mse.params\"\n",
    "best_test_loss = 10e5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = gluon.loss.L2Loss()\n",
    "epochs = 106\n",
    "best_epoch = 0\n",
    "learning_rate = 0.00005\n",
    "log_dir = \"./logs/paragraph_segmentation2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = gluon.Trainer(net.collect_params(), 'adam', {'learning_rate': learning_rate})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for X_batch, y_batch in train_data:\n",
    "    print(\"X_batch has shape {}, and y_batch has shape {}\".format(X_batch.shape, y_batch.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Before for loop, number of epochs is \",epochs)\n",
    "for e in range(epochs):\n",
    "    print(\"epoch\")\n",
    "    train_loss = run_epoch(e, net, train_data, loss_function=loss_function, log_dir=log_dir, \n",
    "                           trainer=trainer, print_name=\"train\", is_train=True)\n",
    "    print(\"Train done\")\n",
    "    test_loss = run_epoch(e, net, test_data, loss_function=loss_function, log_dir=log_dir,\n",
    "                          trainer=trainer, print_name=\"test\", is_train=False)\n",
    "    print(\"Test done\")\n",
    "    if test_loss < best_test_loss:\n",
    "        print(\"Saving network, previous best test loss {:.6f}, current test loss {:.6f}\".format(best_test_loss, test_loss))\n",
    "        net.save_parameters(os.path.join(model_checkpoint_folder, checkpoint_name))\n",
    "        best_epoch = e\n",
    "        best_test_loss = test_loss\n",
    "    if e % print_every_n == 0 and e > 0:\n",
    "        print(\"Epoch {0}, train_loss {1:.6f}, test_loss {2:.6f}\".format(e, train_loss, test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(best_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.export(\"model_export/cnn_mse\", epoch=best_epoch)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
